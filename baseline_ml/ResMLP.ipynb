{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239583ae-1f84-4666-9d14-7ea6a421554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 20:04:31.415754: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79ae1ede-9ab1-48bb-bd8d-f97906474bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self,num_blocks = 6,re_dim = 512):\n",
    "        \"\"\"\n",
    "    Args:\n",
    "      num_blocks: numbers of building blocks for the dense layers.\n",
    "\n",
    "      re_dim: dimension reduction. If int, then for each residue connection, concate with inputs after dimension reduction\n",
    "\n",
    "    Returns:\n",
    "      A `keras.Model` instance.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_blocks = num_blocks\n",
    "        self.re_dim = re_dim\n",
    "        \n",
    "        # init dense layers \n",
    "        self.init_dense = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "    ])     \n",
    "        # You can add new dense block with different parameters and Dropout layers\n",
    "        \n",
    "        # dense layers for dimension reduction and concate (serves as PCA in stacking)\n",
    "        self.dense2 = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(self.re_dim * 4, activation='relu'),\n",
    "        layers.Dense(self.re_dim, activation='relu'),\n",
    "        layers.Dense(self.re_dim, activation='relu'),\n",
    "    ])\n",
    "\n",
    "        # module list\n",
    "        self.dense_block = [\n",
    "                keras.Sequential(\n",
    "            [  \n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "                layers.LayerNormalization(),\n",
    "                layers.Dense(128, activation='relu'),\n",
    "            ]) for _ in range(self.num_blocks)\n",
    "        ]\n",
    "        \n",
    "        # residue concate\n",
    "        self.concate = layers.Concatenate()\n",
    "            \n",
    "        # final dense layer\n",
    "        self.final_dense = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='linear'),\n",
    "    ] )\n",
    "    \n",
    "    def call(self, inputs):\n",
    "\n",
    "        x = self.init_dense(inputs)\n",
    "        x_dim = self.dense2(inputs)\n",
    "        new_x = self.concate([x_dim,x])\n",
    "\n",
    "        for layers in self.dense_block:\n",
    "\n",
    "            x = layers(new_x)\n",
    "\n",
    "            new_x = self.concate([new_x, x])\n",
    "\n",
    "        return self.final_dense(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f4173-93b4-45c5-a981-26339c59bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "model = MLP()\n",
    "inputs = tf.random.normal([12,1024], 0, 1, tf.float32, seed=1)\n",
    "model(inputs)\n",
    "model.compile(loss=root_mean_squared_error,optimizer=Adam(0.001))\n",
    "# compile and train like normal APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fba123-52c5-4213-aca8-b8a04fca5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Add\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import cast,float32\n",
    "from keras import backend as kb\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96d515c-25f1-467a-9d56-0697a12236cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kmer_multiple(seqlist,k):\n",
    "    kmer_list = []\n",
    "    n = -1\n",
    "    for seq in seqlist:\n",
    "        kmer_list.append(generate_kmer_single(seq,k))\n",
    "    return kmer_list\n",
    "    \n",
    "def generate_kmer_single(seq,k):\n",
    "    kmer = \"\"\n",
    "    for i in range(0,len(seq)-k,1):\n",
    "        kmer += seq[i:i+k]+\" \"\n",
    "    return kmer[:-1]\n",
    "\n",
    "def test_rmse(model,X_test,Y_test):\n",
    "    test_preds = model.predict(X_test)\n",
    "    mse = mean_squared_error(Y_test, test_preds)\n",
    "    rmse = sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    y_true = cast(y_true,float32)\n",
    "    return kb.sqrt(kb.mean(kb.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd0754d-2ebd-4b19-a6d9-10f721128697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(da,i,multiplicand):\n",
    "    X_test = da[\"sequence\"].loc[i*multiplicand:(i+1)*multiplicand]\n",
    "    Y_test = da[\"copy_number\"].loc[i*multiplicand:(i+1)*multiplicand]\n",
    "    X_train = pd.concat([da[\"sequence\"].loc[0:i*multiplicand],\n",
    "                         da[\"sequence\"].loc[(i+1)*multiplicand:]],axis = 0)\n",
    "    Y_train = pd.concat([da[\"copy_number\"].loc[0:i*multiplicand],\n",
    "                         da[\"copy_number\"].loc[(i+1)*multiplicand:]],axis = 0)\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    X_train = X_train.values.reshape(X_train.shape[0], )\n",
    "    X_test = X_test.values.reshape(X_test.shape[0], )\n",
    "    kmer_train = generate_kmer_multiple(X_train.tolist(), 6)\n",
    "    kmer_test = generate_kmer_multiple(X_test.tolist(), 6)\n",
    "    X_train = vectorizer.fit_transform(kmer_train).toarray()\n",
    "    X_test = vectorizer.transform(kmer_test).toarray()\n",
    "    return X_train,Y_train,X_test,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c143c6d-8483-4eb5-bef0-4b92e74ac1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "multiplicand = int(da.shape[0]*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bada453d-2bf0-48a3-9563-0862461c4d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 8ms/step\n",
      "0.7079146122285779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 7ms/step\n",
      "0.7893465638895595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 8ms/step\n",
      "0.6884118099897429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 2s 8ms/step\n",
      "0.7187855791058497\n",
      "122/122 [==============================] - 2s 7ms/step\n",
      "0.7256888219162198\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "for i in range(0,5,1):\n",
    "    X_train,Y_train,X_test,Y_test=split_test_train(da,i,multiplicand)\n",
    "    model = MLP(num_blocks = 12,re_dim = 512)\n",
    "    model.compile(loss=root_mean_squared_error,optimizer=Adam(0.001))\n",
    "    model.fit(X_train,Y_train,validation_split=0.1, batch_size=100,epochs=50,verbose=0)\n",
    "    pred = model.predict(X_test)\n",
    "    rmse.append(sqrt(mean_squared_error(Y_test,pred)))\n",
    "    print(rmse[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "32946dec-f987-437f-b19c-86ac2b55dde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72602947742599"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d04aa0-362c-4337-a9f3-d86687b1d209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7079146122285779,\n",
       " 0.7893465638895595,\n",
       " 0.6884118099897429,\n",
       " 0.7187855791058497,\n",
       " 0.7256888219162198]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
