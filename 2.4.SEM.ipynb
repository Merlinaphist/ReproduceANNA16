{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:09:30.462686: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import cast,float32\n",
    "from keras import backend as kb\n",
    "from statistics import mean, stdev\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyNumberPredictor():\n",
    "    def __init__(self,region):\n",
    "        self.region = region\n",
    "        self.state = [59, 0.00016770313599, 0.11, 100, 489, 1, 926, 0, 645, 0, 929, 3, 582, 1, 82, 4]\n",
    "        self.activation_indices={0:\"relu\",1:\"gelu\",2:\"selu\",3:\"elu\",4:\"linear\"}\n",
    "        self.mlp = self.create_mlp()\n",
    "        self.ridge = Ridge(alpha = 49)\n",
    "        self.pca = PCA(n_components=100)\n",
    "        self.svr = SVR(kernel='rbf',C=11,gamma='auto')\n",
    "        \n",
    "    def save(self,filename):\n",
    "        if filename[-4:] != \".zip\":\n",
    "            raise ValueError('Invalid filename. Expect a zip file.')\n",
    "            \n",
    "        path = filename[:-4]\n",
    "        prefix = path + \"/\" + self.region\n",
    "            \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        with open(prefix+'_pca.pkl','wb') as file:\n",
    "            pickle.dump(self.pca,file)\n",
    "        with open(prefix+'_ridge.pkl','wb') as file:\n",
    "            pickle.dump(self.ridge,file)\n",
    "        with open(prefix+'_svr.pkl','wb') as file:\n",
    "            pickle.dump(self.svr,file)\n",
    "        self.mlp.save(prefix+\"_mlp.h5\")\n",
    "        \n",
    "        shutil.make_archive(path, 'zip', path)\n",
    "        shutil.rmtree(path)\n",
    "            \n",
    "    def load(self,filename):\n",
    "        if filename[-4:] != \".zip\":\n",
    "            raise ValueError('Invalid input file. Expect a zip file.')\n",
    "            \n",
    "        path = filename[:-4]\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        with ZipFile(filename,'r') as zObject:\n",
    "            zObject.extractall(path=path)\n",
    "        \n",
    "        prefix = path + \"/\" + self.region\n",
    "        with open(prefix+'_pca.pkl', 'rb') as file:\n",
    "            self.pca = pickle.load(file) \n",
    "        with open(prefix+'_ridge.pkl', 'rb') as file:\n",
    "            self.ridge = pickle.load(file)\n",
    "        with open(prefix+'_svr.pkl', 'rb') as file:\n",
    "            self.svr = pickle.load(file)\n",
    "        self.mlp = load_model(prefix + \"_mlp.h5\",\n",
    "                              custom_objects={\"root_mean_squared_error\": self.root_mean_squared_error})\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "    def fit(self,X_train,Y_train,verbose=True):\n",
    "        self.echo(text = \"------Training Starts------\", verbose = verbose)\n",
    "        X_train_pca = self.pca.fit_transform(X_train)\n",
    "        self.fit_mlp(X_train,Y_train)\n",
    "        mlp_pred = self.mlp.predict(X_train,verbose=0)\n",
    "        self.echo(text = \"Model 1: MLP done.\", verbose = verbose)\n",
    "        \n",
    "        reshaped_Y_train = Y_train.values.reshape(Y_train.shape[0])\n",
    "        new_X_train = pd.concat([pd.DataFrame(X_train_pca),pd.DataFrame(mlp_pred)], axis = 1)\n",
    "        \n",
    "        signals = [\"Model 2: SVR done.\"]\n",
    "        for model in [self.svr]:\n",
    "            model.fit(X_train_pca,reshaped_Y_train)\n",
    "            pred = model.predict(X_train_pca)\n",
    "            new_X_train = pd.concat([new_X_train, pd.DataFrame(pred)], axis = 1)\n",
    "            self.echo(text = signals[0], verbose = verbose)\n",
    "            del signals[0]\n",
    "        \n",
    "        self.ridge.fit(new_X_train,reshaped_Y_train)\n",
    "        self.echo(text = \"Meta-Model: Ridge done.\", verbose = verbose)\n",
    "    \n",
    "    def echo(self,text,verbose):\n",
    "        if verbose not in [True,False]:\n",
    "            raise ValueError('verbose must be True or False')\n",
    "        if verbose:\n",
    "            print(text)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        X_test_pca = self.pca.transform(X_test)\n",
    "        mlp_pred = self.mlp.predict(X_test,verbose=0)\n",
    "        new_X_test = pd.concat([pd.DataFrame(X_test_pca),pd.DataFrame(mlp_pred)], axis = 1)\n",
    "        \n",
    "        for model in [self.svr]:\n",
    "            pred = model.predict(X_test_pca)\n",
    "            new_X_test = pd.concat([new_X_test, pd.DataFrame(pred)], axis = 1)\n",
    "            \n",
    "        final_pred = self.ridge.predict(new_X_test)\n",
    "        return final_pred\n",
    "    \n",
    "    def create_mlp(self):\n",
    "        learning_rate = self.state[1]\n",
    "        model = Sequential()\n",
    "        for i in range(4,len(self.state),2):\n",
    "            n_neurons = self.state[i]\n",
    "            activation = self.activation_indices[self.state[i+1]]\n",
    "            if n_neurons != 0:\n",
    "                model.add(Dense(n_neurons,activation=activation))\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "        model.compile(loss=self.root_mean_squared_error,optimizer=Adam(learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def root_mean_squared_error(self, y_true, y_pred):\n",
    "        y_true = cast(y_true,float32)\n",
    "        return kb.sqrt(kb.mean(kb.square(y_pred - y_true)))\n",
    "    \n",
    "    def fit_mlp(self,X_train,Y_train):\n",
    "        epochs = self.state[0]\n",
    "        validation_split = self.state[2]\n",
    "        batch_size = self.state[3]\n",
    "        self.mlp.fit(X_train,Y_train,validation_split=validation_split,\n",
    "                     batch_size=batch_size,epochs=epochs,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 09:09:41.397796: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 09:09:41.911761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9651 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:3d:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6763061242996811\n",
      "0.7354001494547514\n",
      "0.6297395471687893\n",
      "0.6895670932190365\n",
      "0.6926191879388353\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "for i in range(5):\n",
    "    X_train = pd.read_csv(\"datasets/splits/X_train_{}.csv\".format(str(i)))\n",
    "    Y_train = pd.read_csv(\"datasets/splits/Y_train_{}.csv\".format(str(i)))\n",
    "    X_test = pd.read_csv(\"datasets/splits/X_test_{}.csv\".format(str(i)))\n",
    "    Y_test = pd.read_csv(\"datasets/splits/Y_test_{}.csv\".format(str(i)))\n",
    "    model = CopyNumberPredictor()\n",
    "    model.fit(X_train,Y_train,verbose=False)\n",
    "    pred = model.predict(X_test)\n",
    "    rmse.append(sqrt(mean_squared_error(Y_test,pred)))\n",
    "    print(rmse[i])\n",
    "    pred_records = np.array([Y_test,pred]).transpose()\n",
    "    pred_records = pd.DataFrame(pred_records)\n",
    "    pred_records.columns = [\"Y_test\",\"Y_pred\"]\n",
    "    pred_records[\"group\"] = i\n",
    "    pred_records.to_csv(\"pred_records/full_length_pred_records_{}.csv\".format(str(i)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6847264204162187"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6763061242996811,\n",
       " 0.7354001494547514,\n",
       " 0.6297395471687893,\n",
       " 0.6895670932190365,\n",
       " 0.6926191879388353]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rmse,\n",
    "             columns = [\"smac_full_length\"]).to_csv(\"performance/smac_universal_full_length.csv\",\n",
    "                                                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
