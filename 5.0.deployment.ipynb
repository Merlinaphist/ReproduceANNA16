{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle, os, shutil\n",
    "from zipfile import ZipFile\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import cast,float32\n",
    "from keras import backend as kb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_region_train(region):\n",
    "    da = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "    file_handle = open(\"datasets/\"+region+\".fasta\",\"r\")\n",
    "    seq = []\n",
    "    seqid = []\n",
    "    tmp_seq = \"\"\n",
    "    for line in file_handle:\n",
    "        if (line[0] == \">\"):\n",
    "            if tmp_seq != \"\":\n",
    "                seq.append(tmp_seq)\n",
    "            seqid.append(line.split(\"\\n\")[0][1:])\n",
    "            tmp_seq = \"\"\n",
    "        else:\n",
    "            tmp_seq+=line.split(\"\\n\")[0]\n",
    "    seq.append(tmp_seq)\n",
    "    file_handle.close()\n",
    "    sub = pd.DataFrame([seq,seqid], index = [region,\"accession\"])\n",
    "    sub = sub.transpose()\n",
    "    da = da[[\"accession\",\"copy_number\"]]\n",
    "    da = pd.merge(da,sub,on=\"accession\",how=\"inner\")\n",
    "    return da\n",
    "\n",
    "def read_region_test(region):\n",
    "    da = pd.read_csv(\"datasets/full_length_testdata.csv\")\n",
    "    file_handle = open(\"datasets/\"+region+\"_testdata.fasta\",\"r\")\n",
    "    seq = []\n",
    "    seqid = []\n",
    "    tmp_seq = \"\"\n",
    "    for line in file_handle:\n",
    "        if (line[0] == \">\"):\n",
    "            if tmp_seq != \"\":\n",
    "                seq.append(tmp_seq)\n",
    "            seqid.append(line.split(\"\\n\")[0][1:])\n",
    "            tmp_seq = \"\"\n",
    "        else:\n",
    "            tmp_seq+=line.split(\"\\n\")[0]\n",
    "    seq.append(tmp_seq)\n",
    "    file_handle.close()\n",
    "    sub = pd.DataFrame([seq,seqid], index = [region,\"accession\"])\n",
    "    sub = sub.transpose()\n",
    "    da = da[[\"accession\",\"copy_number\"]]\n",
    "    da = pd.merge(da,sub,on=\"accession\",how=\"inner\")\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self,k_size=6):\n",
    "        self.k_size = k_size\n",
    "        kmers = self.generate_kmers(\"\",self.k_size)\n",
    "        self.vectorizer = CountVectorizer(vocabulary = kmers)\n",
    "        self.seqs = []\n",
    "    \n",
    "    def generate_kmers(self,current_kmer,current_depth):\n",
    "        if current_depth == 1:\n",
    "            return [current_kmer+\"a\",current_kmer+\"t\",current_kmer+\"c\",current_kmer+\"g\"]\n",
    "        else:\n",
    "            ret = self.generate_kmers(current_kmer+\"a\",current_depth-1)\n",
    "            for nt in ['t','c','g']:\n",
    "                ret += self.generate_kmers(current_kmer+nt,current_depth-1)\n",
    "            return ret\n",
    "        \n",
    "    def generate_kmer_multiple(self,seqlist,k):\n",
    "        kmer_list = []\n",
    "        n = -1\n",
    "        for seq in seqlist:\n",
    "            kmer_list.append(self.generate_kmer_single(str(seq),k))\n",
    "        return kmer_list\n",
    "    \n",
    "    def generate_kmer_single(self,seq,k):\n",
    "        kmer = \"\"\n",
    "        for i in range(0,len(seq)-k,1):\n",
    "            kmer += seq[i:i+k]+\" \"\n",
    "        return kmer[:-1]\n",
    "    \n",
    "    def CountKmers(self,seqs):\n",
    "        if type(seqs) in [type([]),type(pd.core.series.Series([1]))]:\n",
    "            kmer = self.generate_kmer_multiple(seqs, self.k_size)\n",
    "            transformed_X = self.vectorizer.transform(kmer).toarray()\n",
    "            return transformed_X\n",
    "        else:\n",
    "            raise ValueError(\"Invalid 'seqs' format. Expected formats are 'list' or 'pandas.core.series.Series'.\")\n",
    "            \n",
    "    def ReadFASTA(self,filename,as_pd=True):\n",
    "        if filename.split(\".\")[-1] not in [\"fasta\",\"fna\",\"fa\"]:\n",
    "            raise ValueError('Invalid file format. Expected formats are [\"fasta\",\"fna\",\"fa\"].')\n",
    "        file_handle = open(filename,\"r\")\n",
    "        seqs = []\n",
    "        seqid = []\n",
    "        tmp_seq = \"\"\n",
    "        for line in file_handle:\n",
    "            if (line[0] == \">\"):\n",
    "                if tmp_seq != \"\":\n",
    "                    seqs.append(tmp_seq)\n",
    "                seqid.append(line.split(\"\\n\")[0][1:])\n",
    "                tmp_seq = \"\"\n",
    "            else:\n",
    "                tmp_seq+=line.split(\"\\n\")[0]\n",
    "        seqs.append(tmp_seq)\n",
    "        file_handle.close()\n",
    "        if as_pd:\n",
    "            fasta = {}\n",
    "            for i in range(len(seqs)):\n",
    "                fasta[seqid[i]] = seqs[i]\n",
    "            return pd.DataFrame(fasta,index=[\"sequence\"]).transpose()[\"sequence\"]\n",
    "        else:\n",
    "            return seqs, seqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CopyNumberPredictor():\n",
    "    def __init__(self):\n",
    "        self.state = [59, 0.00016770313599, 0.11, 100, 489, 1, 926, 0, 645, 0, 929, 3, 582, 1, 82, 4]\n",
    "        self.activation_indices={0:\"relu\",1:\"gelu\",2:\"selu\",3:\"elu\",4:\"linear\"}\n",
    "        self.mlp = self.create_mlp()\n",
    "        self.ridge = Ridge(alpha = 49)\n",
    "        self.pca = PCA(n_components=100)\n",
    "        self.svr = SVR(kernel='rbf',C=11,gamma='auto')\n",
    "        \n",
    "    def save(self,filename):\n",
    "        if filename[-4:] != \".zip\":\n",
    "            raise ValueError('Invalid filename. Expect a zip file.')\n",
    "            \n",
    "        path = filename[:-4]\n",
    "        prefix = path + \"/\" + self.region\n",
    "            \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        with open(prefix+'_pca.pkl','wb') as file:\n",
    "            pickle.dump(self.pca,file)\n",
    "        with open(prefix+'_ridge.pkl','wb') as file:\n",
    "            pickle.dump(self.ridge,file)\n",
    "        with open(prefix+'_svr.pkl','wb') as file:\n",
    "            pickle.dump(self.svr,file)\n",
    "        self.mlp.save(prefix+\"_mlp.h5\")\n",
    "        \n",
    "        shutil.make_archive(path, 'zip', path)\n",
    "        shutil.rmtree(path)\n",
    "            \n",
    "    def load(self,filename):\n",
    "        if filename[-4:] != \".zip\":\n",
    "            raise ValueError('Invalid input file. Expect a zip file.')\n",
    "            \n",
    "        path = filename[:-4]\n",
    "        \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        \n",
    "        with ZipFile(filename,'r') as zObject:\n",
    "            zObject.extractall(path=path)\n",
    "        \n",
    "        prefix = path + \"/\" + self.region\n",
    "        with open(prefix+'_pca.pkl', 'rb') as file:\n",
    "            self.pca = pickle.load(file) \n",
    "        with open(prefix+'_ridge.pkl', 'rb') as file:\n",
    "            self.ridge = pickle.load(file)\n",
    "        with open(prefix+'_svr.pkl', 'rb') as file:\n",
    "            self.svr = pickle.load(file)\n",
    "        self.mlp = load_model(prefix + \"_mlp.h5\",\n",
    "                              custom_objects={\"root_mean_squared_error\": self.root_mean_squared_error})\n",
    "        shutil.rmtree(path)\n",
    "        \n",
    "    def fit(self,X_train,Y_train,verbose=True):\n",
    "        self.echo(text = \"------Training Starts------\", verbose = verbose)\n",
    "        X_train_pca = self.pca.fit_transform(X_train)\n",
    "        self.fit_mlp(X_train,Y_train)\n",
    "        mlp_pred = self.mlp.predict(X_train,verbose=0)\n",
    "        self.echo(text = \"Model 1: MLP done.\", verbose = verbose)\n",
    "        \n",
    "        reshaped_Y_train = Y_train.values.reshape(Y_train.shape[0])\n",
    "        new_X_train = pd.concat([pd.DataFrame(X_train_pca),pd.DataFrame(mlp_pred)], axis = 1)\n",
    "        \n",
    "        signals = [\"Model 2: SVR done.\"]\n",
    "        for model in [self.svr]:\n",
    "            model.fit(X_train_pca,reshaped_Y_train)\n",
    "            pred = model.predict(X_train_pca)\n",
    "            new_X_train = pd.concat([new_X_train, pd.DataFrame(pred)], axis = 1)\n",
    "            self.echo(text = signals[0], verbose = verbose)\n",
    "            del signals[0]\n",
    "        \n",
    "        self.ridge.fit(new_X_train,reshaped_Y_train)\n",
    "        self.echo(text = \"Meta-Model: Ridge done.\", verbose = verbose)\n",
    "    \n",
    "    def echo(self,text,verbose):\n",
    "        if verbose not in [True,False]:\n",
    "            raise ValueError('verbose must be True or False')\n",
    "        if verbose:\n",
    "            print(text)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        X_test_pca = self.pca.transform(X_test)\n",
    "        mlp_pred = self.mlp.predict(X_test,verbose=0)\n",
    "        new_X_test = pd.concat([pd.DataFrame(X_test_pca),pd.DataFrame(mlp_pred)], axis = 1)\n",
    "        \n",
    "        for model in [self.svr]:\n",
    "            pred = model.predict(X_test_pca)\n",
    "            new_X_test = pd.concat([new_X_test, pd.DataFrame(pred)], axis = 1)\n",
    "            \n",
    "        final_pred = self.ridge.predict(new_X_test)\n",
    "        return final_pred\n",
    "    \n",
    "    def create_mlp(self):\n",
    "        learning_rate = self.state[1]\n",
    "        model = Sequential()\n",
    "        for i in range(4,len(self.state),2):\n",
    "            n_neurons = self.state[i]\n",
    "            activation = self.activation_indices[self.state[i+1]]\n",
    "            if n_neurons != 0:\n",
    "                model.add(Dense(n_neurons,activation=activation))\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "        model.compile(loss=self.root_mean_squared_error,optimizer=Adam(learning_rate))\n",
    "        return model\n",
    "    \n",
    "    def root_mean_squared_error(self, y_true, y_pred):\n",
    "        y_true = cast(y_true,float32)\n",
    "        return kb.sqrt(kb.mean(kb.square(y_pred - y_true)))\n",
    "    \n",
    "    def fit_mlp(self,X_train,Y_train):\n",
    "        epochs = self.state[0]\n",
    "        validation_split = self.state[2]\n",
    "        batch_size = self.state[3]\n",
    "        self.mlp.fit(X_train,Y_train,validation_split=validation_split,\n",
    "                     batch_size=batch_size,epochs=epochs,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Training Starts------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 00:48:43.841958: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n",
      "------Training Starts------\n",
      "Model 1: MLP done.\n",
      "Model 2: SVR done.\n",
      "Meta-Model: Ridge done.\n"
     ]
    }
   ],
   "source": [
    "da0 = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "da1 = pd.read_csv(\"4.final_test/datasets/full_length_testdata.csv\")\n",
    "da = pd.concat([da0,da1],axis=0)\n",
    "da = da.sample(frac=1,random_state=114514)\n",
    "model = CopyNumberPredictor()\n",
    "X = da[\"sequence\"]\n",
    "Y = da['copy_number']\n",
    "pp = Preprocessing()\n",
    "X = pp.CountKmers(seqs=X)\n",
    "model.fit(X,Y)\n",
    "model.save(filename=\"6.mock_community/deployment/full_length.zip\")\n",
    "for region in [\"V1-V2\",\"V1-V3\",\"V3-V4\",\"V4\",\"V4-V5\",\"V6-V8\",\"V7-V9\"]:\n",
    "    da0 = read_region_train(region)\n",
    "    da1 = read_region_test(region)\n",
    "    da = pd.concat([da0,da1],axis=0)\n",
    "    da = da.sample(frac=1,random_state=114514)\n",
    "    model = CopyNumberPredictor()\n",
    "    X = da[region]\n",
    "    Y = da['copy_number']\n",
    "    X = pp.CountKmers(seqs=X)\n",
    "    model.fit(X,Y)\n",
    "    model.save(filename=\"6.mock_community/deployment/{}.zip\".format(region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
