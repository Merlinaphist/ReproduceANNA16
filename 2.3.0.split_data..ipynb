{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaojiazheng/Downloads/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import cast,float32\n",
    "from keras import backend as kb\n",
    "from statistics import mean, stdev\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorflow.keras import Input, Model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing():\n",
    "    def __init__(self,k_size=6):\n",
    "        self.k_size = k_size\n",
    "        kmers = self.generate_kmers(\"\",self.k_size)\n",
    "        self.vectorizer = CountVectorizer(vocabulary = kmers)\n",
    "        self.seqs = []\n",
    "    \n",
    "    def generate_kmers(self,current_kmer,current_depth):\n",
    "        if current_depth == 1:\n",
    "            return [current_kmer+\"a\",current_kmer+\"t\",current_kmer+\"c\",current_kmer+\"g\"]\n",
    "        else:\n",
    "            ret = self.generate_kmers(current_kmer+\"a\",current_depth-1)\n",
    "            for nt in ['t','c','g']:\n",
    "                ret += self.generate_kmers(current_kmer+nt,current_depth-1)\n",
    "            return ret\n",
    "    \n",
    "    def generate_kmer_multiple(self,seqlist,k):\n",
    "        kmer_list = []\n",
    "        n = -1\n",
    "        for seq in seqlist:\n",
    "            kmer_list.append(self.generate_kmer_single(str(seq),k))\n",
    "        return kmer_list\n",
    "    \n",
    "    def generate_kmer_single(self,seq,k):\n",
    "        kmer = \"\"\n",
    "        for i in range(0,len(seq)-k,1):\n",
    "            kmer += seq[i:i+k]+\" \"\n",
    "        return kmer[:-1]\n",
    "    \n",
    "    def CountKmers(self,seqs):\n",
    "        if type(seqs) in [type([]),type(pd.core.series.Series([1]))]:\n",
    "            kmer = self.generate_kmer_multiple(seqs, self.k_size)\n",
    "            transformed_X = self.vectorizer.transform(kmer).toarray()\n",
    "            return transformed_X\n",
    "        else:\n",
    "            raise ValueError(\"\"\"Invalid 'seqs' format.\n",
    "            Expected formats are 'list' or 'pandas.core.series.Series'.\"\"\")\n",
    "            \n",
    "    def ReadFASTA(self,filename,as_pd=True):\n",
    "        if filename.split(\".\")[-1] not in [\"fasta\",\"fna\",\"fa\"]:\n",
    "            raise ValueError('Invalid file format. Expected formats are [\"fasta\",\"fna\",\"fa\"].')\n",
    "        file_handle = open(filename,\"r\")\n",
    "        seqs = []\n",
    "        seqid = []\n",
    "        tmp_seq = \"\"\n",
    "        for line in file_handle:\n",
    "            if (line[0] == \">\"):\n",
    "                if tmp_seq != \"\":\n",
    "                    seqs.append(tmp_seq)\n",
    "                seqid.append(line.split(\"\\n\")[0][1:])\n",
    "                tmp_seq = \"\"\n",
    "            else:\n",
    "                tmp_seq+=line.split(\"\\n\")[0]\n",
    "        seqs.append(tmp_seq)\n",
    "        file_handle.close()\n",
    "        if as_pd:\n",
    "            fasta = {}\n",
    "            for i in range(len(seqs)):\n",
    "                fasta[seqid[i]] = seqs[i]\n",
    "            return pd.DataFrame(fasta,index=[\"sequence\"]).transpose()[\"sequence\"]\n",
    "        else:\n",
    "            return seqs, seqid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(da,multiplicand):\n",
    "    pp = Preprocessing()\n",
    "    for i in range(0,5,1):\n",
    "        X_test = da[\"sequence\"].loc[i*multiplicand:(i+1)*multiplicand]\n",
    "        Y_test = da[\"copy_number\"].loc[i*multiplicand:(i+1)*multiplicand]\n",
    "        X_train = pd.concat([da[\"sequence\"].loc[0:i*multiplicand],\n",
    "                             da[\"sequence\"].loc[(i+1)*multiplicand:]],axis = 0)\n",
    "        Y_train = pd.concat([da[\"copy_number\"].loc[0:i*multiplicand],\n",
    "                             da[\"copy_number\"].loc[(i+1)*multiplicand:]],axis = 0)\n",
    "        X_train = pp.CountKmers(seqs=X_train)\n",
    "        X_test = pp.CountKmers(seqs=X_test)\n",
    "        pd.DataFrame(X_train).to_pickle(f\"datasets/splits/X_train_{i}.gz\")\n",
    "        pd.DataFrame(Y_train).to_pickle(f\"datasets/splits/Y_train_{i}.gz\")\n",
    "        pd.DataFrame(X_test).to_pickle(f\"datasets/splits/X_test_{i}.gz\")\n",
    "        pd.DataFrame(Y_test).to_pickle(f\"datasets/splits/Y_test_{i}.gz\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "multiplicand = int(da.shape[0]*0.2)\n",
    "split_test_train(da,multiplicand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = Preprocessing()\n",
    "da1 = pd.read_csv(\"4.final_test/datasets/full_length_testdata.filtered.csv\")\n",
    "X0 = da[\"sequence\"]\n",
    "Y0 = da['copy_number']\n",
    "X1 = da1[\"sequence\"]\n",
    "Y1 = da1['copy_number']\n",
    "X0 = pp.CountKmers(X0)\n",
    "X1 = pp.CountKmers(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X0).to_pickle(\"4.final_test/datasets/X_final_train.gz\")\n",
    "pd.DataFrame(Y0).to_pickle(\"4.final_test/datasets/Y_final_train.gz\")\n",
    "pd.DataFrame(X1).to_pickle(\"4.final_test/datasets/X_final_test.gz\")\n",
    "pd.DataFrame(Y1).to_pickle(\"4.final_test/datasets/Y_final_test.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/miaojiazheng/Downloads/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocal = {\n",
    "#     'A':[1,0,0,0],\n",
    "#     'T':[0,1,0,0],\n",
    "#     'C':[0,0,1,0],\n",
    "#     'G':[0,0,0,1],\n",
    "    \n",
    "#     'R':[0.5,0,0,0.5],\n",
    "#     'K':[0,0.5,0,0.5],\n",
    "#     'S':[0,0,0.5,0.5],\n",
    "#     'Y':[0,0.5,0.5,0],\n",
    "#     'M':[0.5,0,0.5,0],\n",
    "#     'W':[0.5,0.5,0,0],\n",
    "#     'B':[0,0.33,0.33,0.33],\n",
    "#     'H':[0.33,0.33,0.33,0],\n",
    "#     'N':[0.25,0.25,0.25,0.25],\n",
    "#     'D':[0.33,0.33,0,0.33],\n",
    "#     \"V\":[0.33,0,0.33,0.33]\n",
    "# }\n",
    "\n",
    "vocal = {\n",
    "    'A':1,\n",
    "    'T':2,\n",
    "    'C':3,\n",
    "    'G':4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = pd.read_csv(\"datasets/full_length_reads.csv\")\n",
    "multiplicand = int(da.shape[0]*0.2)\n",
    "da1 = pd.read_csv(\"4.final_test/datasets/full_length_testdata.filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = max(da[\"sequence\"].apply(len).max(), da1[\"sequence\"].apply(len).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncode(X, maxlen):\n",
    "    EncodedX = []\n",
    "    for seq in X.tolist():\n",
    "        EncodedLine = []\n",
    "        for char in list(seq):\n",
    "            EncodedLine.append(vocal.get(char,5))\n",
    "        EncodedLine = EncodedLine + [0] * (maxlen - len(EncodedLine)) \n",
    "        EncodedX.append(EncodedLine)\n",
    "    EncodedX = np.array(EncodedX)\n",
    "    return EncodedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train_onehot(X,Y,multiplicand):\n",
    "    for i in range(0,5,1):\n",
    "        X_test = X[i*multiplicand:(i+1)*multiplicand]\n",
    "        Y_test = Y[i*multiplicand:(i+1)*multiplicand]\n",
    "        X_train = np.concatenate([X[0:i*multiplicand],\n",
    "                             X[(i+1)*multiplicand:]],axis = 0)\n",
    "        Y_train = np.concatenate([Y[0:i*multiplicand],\n",
    "                             Y[(i+1)*multiplicand:]],axis = 0)\n",
    "        pd.DataFrame(X_train).to_pickle(f\"datasets/onehot/X_train_{i}.gz\")\n",
    "        pd.DataFrame(Y_train).to_pickle(f\"datasets/onehot/Y_train_{i}.gz\")\n",
    "        pd.DataFrame(X_test).to_pickle(f\"datasets/onehot/X_test_{i}.gz\")\n",
    "        pd.DataFrame(Y_test).to_pickle(f\"datasets/onehot/Y_test_{i}.gz\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = OneHotEncode(da[\"sequence\"], maxlen)\n",
    "X1 = OneHotEncode(da1[\"sequence\"], maxlen)\n",
    "Y0 = da['copy_number']\n",
    "Y1 = da1['copy_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_test_train_onehot(X0, Y0, multiplicand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19520, 2402)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X0).to_pickle(\"4.final_test/datasets/X_final_train_onehot.gz\")\n",
    "pd.DataFrame(Y0).to_pickle(\"4.final_test/datasets/Y_final_train_onehot.gz\")\n",
    "pd.DataFrame(X1).to_pickle(\"4.final_test/datasets/X_final_test_onehot.gz\")\n",
    "pd.DataFrame(Y1).to_pickle(\"4.final_test/datasets/Y_final_test_onehot.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
